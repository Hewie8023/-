[TOC]

## 物理层

## 数据链路层

## 网络层

## 传输层

### 三次握手
第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。
第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；
第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。

### 四次挥手
1）客户端进程**发出连接释放报文，并且停止发送数据**。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2）服务器**收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v**，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3）客户端**收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态**，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4）服务器将**最后的数据发送完毕后，就向客户端发送连接释放报文**，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5）客户端**收到服务器的连接释放报文后，必须发出确认**，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6）服务器只要**收到了客户端发出的确认，立即进入CLOSED状态**。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

### 为什么连接的时候是三次握手，关闭的时候却是四次握手？
因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

### 为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？
**MSL**（Maximum Segment Lifetime），最长报文段寿命，TCP允许不同的实现可以设置不同的MSL值。
**第一**，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。
**第二**，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。

#### time_wait状态如何避免
首先服务器可以设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口。在一个非常有用的场景就是，如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时SO_REUSEADDR选项就可以避免TIME_WAIT状态。


### 为什么不能用两次握手进行连接？
3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。

现在把三次握手改成仅需要两次握手，死锁是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求分组，S收到了这个分组，并发送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据分 组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。
就好比打电话， A打给B， A要告诉B ，我打给你了， B要回应给A听，OK，连接成功了；然后B也要得到A的确认，才能开始正式通话

### 如果已经建立了连接，但是客户端突然出现故障了怎么办？
TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

### 三次握手的隐患
SYN- Flood攻击是当前网络上最为常见的DDoS攻击，也是最为经典的拒绝服务攻击，它就是利用了TCP协议实现上的一个缺陷，通过向网络服务所在端口发送大量 的伪造源地址的攻击报文，就可能造成目标服务器中的半开连接队列被占满，从而阻止其他合法用户进行访问。
**原理**：攻击者首先伪造地址对服务器发起SYN请求，服务器回应(SYN+ACK)包，而真实的IP会认为，我没有发送请求，不作回应。服务 器没有收到回应，这样的话，服务器不知 道(SYN+ACK)是否发送成功，默认情况下会重试5次（tcp_syn_retries）。这样的话，对于服务器的内存，带宽都有很大的消耗。攻击者如果处于公网，可以伪造IP的话，对于服务器就很难根据IP来判断攻击者，给防护带来很大的困难。

**SYN Flood 防护措施**
1. 无效连接监视释放
这种方法不停的监视系统中半开连接和不活动连接，当达到一定阈值时拆除这些连接，释放系统资源。这种绝对公平的方法往往也会将正常的连接的请求也会被释放掉，”伤敌一千，自损八百“
2. 延缓TCB分配方法
SYN Flood关键是利用了，SYN数据报文一到，系统立即分配TCB资源，从而占用了系统资源，因此有俩种技术来解决这一问题
**Syn Cache技术**
这种技术在收到SYN时不急着去分配TCB，而是先回应一个ACK报文，并在一个专用的HASH表中（Cache）中保存这种半开连接，直到收到正确的ACK报文再去分配TCB
**Syn Cookie技术**
Syn Cookie技术则完全不使用任何存储资源，它使用一种特殊的算法生成Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS、时间等，在收到对方 的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源



### TCP的流量控制：滑动窗口的原理
滑动窗口协议**允许发送方在停止并等待确认前发送多个数据分组**。由于发送方不必每发一个分组（IP数据包或TCP报文段）就停下来等待确认，因此该协议可以加速数据的传输，增大了吞吐量。

停止等待协议是最简单但也是最基础的数据链路层协议。与滑动窗口协议不同的是停止等待协议就是每发送完一个分组就停止发送，等待对方的确认，在收到确认后再发送下一个分组。当发送窗口和接收窗口的大小都等于**1**时，就是停止等待协议。

TCP的可靠数据传输服务确保进程从接收缓冲区中读出的数据流是正确地，有序的，不重复的，即读出的字节流与连接的另一方系统发送的字节流是完全一样的，但是实际上接收方应用进程不一定时刻都在读数据，那么如果应用进程读取数据相当慢，而发送方发送的数据太多、太快，就很容易使接收方的接收缓冲区溢出。所以**TCP采用大小可变的滑动窗口给应用程序提供流量控制服务**，用以消除接收缓冲区溢出的可能。实际上TCP报文段头部的16位窗口字段写入的数值就是接收方当前给对方设置的发送窗口的上限，发送窗口在连接建立时由双方商定，但是在通信过程中，接收方根据自己的接收缓冲区资源大小随时动态的调整对方发送窗口的上限（滑动窗口即可以滑动滴）。

流量控制（用滑动窗口实现）就是让发送方的发送速率不要太快，要让接收方来得及接收。

TCP连接发送方发送一个数据报，对端会进行确认在发送下一个数据包。

举个例子：TCP通信是全双工的，这里为了方便理解，就以一个方向为例，假设A为发送方，B为接收方。A会有一个发送窗口，B有一个接收窗口。在连接建立的时候B告诉A其接收窗口是400字节，因此发送方的发送窗口不能超过接收方给的接收窗口大小。（假设一个报文段100字节，报文段序号初始值为1.图中大写ACK表示头部中的确认位ACK，小写ack表示确认字段的值）
![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B601.png)

为了便于大家看，我们采用另一种方式描述发送窗口，假设A现在收到B的确认报文段，窗口是20字节，确认号是31（表示B期望收到的下一个序号是31，而序号30为止的数据已经收到了），根据此条件，A构造出自己的发送窗口，如下图：
![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B602.png)

**发送窗口表示在没有收到B确认的情况下，A也可以连续把发送窗口的数据发送出去**。但是已经发送过的数据在未收到确认之前，它还需要暂时保留，以便于超时重传时使用。发送窗口越大，它就可以在收到对方确认之前发送更多的数据，因而获得更高的传输效率。（但是接收方要来得及处理之前的数据）

发送窗口的位置由窗口前沿和后沿的位置共同确定。
它后沿变化有两种，（1）不动（没有收到新的确定）（2）前移（收到新的确认）；

前沿是不断向前移动的，但也可能不动
（1）不动（没有收到新确认，对方窗口也不变）
（2）不动（收到新的确认，对方的应用层没有读取数据，接收窗口缩小了，使前沿正好不变，后沿前移窗口就变小了）

假定A发送了序号为31～41的数据。这时，发送窗口的位置并未改变，发送窗口内靠后的11个字节（黑色部分）表示 已发送但未收到确认。
![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B603.png)

即小于P1的是已发送并收到确认的序号，而大于P3的是不允许发送的部分。
P3-P1=A的发送窗口
P2-P1=已发送但是未接收到确认的字节数
P3-P2=允许发送但是未发送的字节数（可用窗口或有效窗口）

再看B的接收窗口大小是20，在接收窗口外面到30号位置的数据是接收并确认的，因此可以丢弃。在接收窗口中，B收到了32和33的数据（白色的是没有接收到的），但它们不是按序到达的，因为并没有收到31号数据。B只能对按序达收到的数据中的最高序号给出确认，因此B发送的确认报文字段的确认号依然是31号（确认号就是告诉发送方期望下一次收到数据包的序号）。

现在假定B收到了序号为31的数据，并把31～33的数据交付主机，然后B删除这些数据。接着把窗口向前移动3个序号，如下图，同时给a发送确认，其中的窗口值仍为20，但确认号变为34。表明B已经收到序号33为止的数据。

![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B604.png)

当A发送完窗口内的所有数据后，未收到任何确认时，窗口内就没有可发送的数据。经过一段时间后（超时计时器），若仍未收到确认，A将会重新发送。

此外发送方和接收方都有自己的缓冲区
**发送缓冲区存放**：
1、发送发TCP准备发送的数据
2、TCP已发送但尚未收到确认的数据（为超时重传准备）

**接收缓冲区存放**：
1、按序到达但未被应用程序读取的数据
2、未按序到达的数据

实际上发送窗口大小不仅仅是由接收端决定的，其还受网络的拥塞程度决定。发送窗口=MIN{接收窗口，拥塞窗口}


### 既然有了拥塞控制,为什么还会有拥塞比如游戏卡顿
https://zhuanlan.zhihu.com/p/59778587
路由器只是把溢出的流量丢弃处理，其他的什么都不做。
源主机发现丢包了，就会将流量降速差不多一半，这就是流量拥塞控制。
但是，是先发生“路由器流量溢出（丢包）”，然后才触发了“源主机的流量拥塞控制”。
源主机的流量拥塞控制（Congestion Control）机制，永远都无法避免路由节点的网络拥塞，从而造成的流量溢出（丢包）！

### TCP粘包、拆包
粘包问题主要还是因为接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。

发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一个TCP段。若连续几次需要send的数据都很少，通常TCP会根据negal优化算法把这些数据合成一个TCP段后一次发送出去，这样接收方就收到了粘包数据。

两种粘包情况：
1. 发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据了很小，会合到一起，产生粘包）
2. 接收方不及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包） 

两种拆包情况：
1. 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
2. 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。

**粘包、拆包解决办法**
通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：
1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。


#### UDP会不会粘包
TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。

### TCP怎么实现的



### TCP和UDP各自的特点
UDP提供不可靠服务，具有TCP所没有的优势：
1、	1、UDP无连接，时间上不存在建立连接需要的时延。空间上，TCP需要在端系统中维护连接状态，需要一定的开销。此连接装入包括接收和发送缓存，拥塞控制参数和序号与确认号的参数。UCP不维护连接状态，也不跟踪这些参数，开销小。空间和时间上都具有优势。
举个例子：
DNS如果运行在TCP之上而不是UDP，那么DNS的速度将会慢很多。
HTTP使用TCP而不是UDP，是因为对于基于文本数据的Web网页来说，可靠性很重要。
同一种专用应用服务器在支持UDP时，一定能支持更多的活动客户机。

2、分组首部开销小，TCP首部20字节，UDP首部8字节。

3、UDP没有拥塞控制，应用层能够更好的控制要发送的数据和发送时间，网络中的拥塞控制也不会影响主机的发送速率。某些实时应用要求以稳定的速度发送，能容忍一些数据的丢失，但是不能允许有较大的时延（比如实时视频，直播等）

4、UDP提供尽最大努力的交付，不保证可靠交付。所有维护传输可靠性的工作需要用户在应用层来完成。没有TCP的确认机制、重传机制。如果因为网络原因没有传送到对端，UDP也不会给应用层返回错误信息

5、UDP是面向报文的，对应用层交下来的报文，添加首部后直接向下交付为IP层，既不合并，也不拆分，保留这些报文的边界。对IP层交上来UDP用户数据报，在去除首部后就原封不动地交付给上层应用进程，报文不可分割，是UDP数据报处理的最小单位。
正是因为这样，UDP显得不够灵活，不能控制读写数据的次数和数量。比如我们要发送100个字节的报文，我们调用一次sendto函数就会发送100字节，对端也需要用recvfrom函数一次性接收100字节，不能使用循环每次获取10个字节，获取十次这样的做法。

6、UDP常用一次性传输比较少量数据的网络应用，如DNS,SNMP等，因为对于这些应用，若是采用TCP，为连接的创建，维护和拆除带来不小的开销。UDP也常用于多媒体应用（如IP电话，实时视频会议，流媒体等）数据的可靠传输对他们而言并不重要，TCP的拥塞控制会使他们有较大的延迟，也是不可容忍的。
7、UDP支持一对一、一对多、多对一和多对多的交互通信。

TCP是一个面向连接的(connection-oriented)、可靠的(reliable)、字节流式(byte stream)传输协议。
	面向连接：在应用TCP协议进行通信之前双方通常需要通过三次握手来建立TCP连接，连接建立后才能进行正常的数据传输，因此广播和多播不会承载在TCP协议上。(谷歌提交了一个RFC文档，建议在TCP三次握手的过程允许SYN数据包中带数据，即 TFO(TCP Fast Open)，目前ubuntu14.04已经支持该TFO功能)。但是同时面向连接的特性给TCP带来了复杂的连接管理以及用于检测连接状态的存活检测机制。
	可靠性：由于TCP处于多跳通信的IP层之上，而IP层并不提供可靠的传输，因此在TCP层看来就有四种常见传输错误问题，分别是比特错误(packet bit errors)、包乱序(packet reordering)、包重复(packet duplication)、丢包(packet erasure或称为packet drops)，TCP要提供可靠的传输，就需要有额外的机制处理这几种错误。因此个人理解可靠性体现在三个方面，首先TCP通过超时重传和快速重传两个常见手段来保证数据包的正确传输，也就是说接收端在没有收到数据包或者收到错误的数据包的时候会触发发送端的数据包重传(处理比特错误和丢包)。其次TCP接收端会缓存接”到的”序到达数据，重排序后在向应用层提供有序的数据(处理包乱序)。最后TCP发送端会维持一个发送"窗口"动态的调整发送速率以适用接收端缓存限制和网络拥塞情况，避免了网络拥塞或者接收端缓存满而大量丢包的问题(降低丢包率)。因此可靠性需要TCP协议具有超时与重传管理、窗口管理、流量控制、拥塞控制等功能。另外TFO下TCP有可能向应用层提供重复的数据，也就是不可靠传输，但是只会发生在连接建立阶段，我们后续会进行介绍。
	字节流式：应用层发送的数据会在TCP的发送端缓存起来，统一分片(例如一个应用层的数据包分成两个TCP包)或者打包(例如两个或者多个应用层的数据包打包成一个TCP数据包)发送，到接收端的时候接收端也是直接按照字节流将数据传递给应用层。作为对比，同样是传输层的协议，UDP并不会对应用层的数据包进行打包和分片的操作，一般一个应用层的数据包就对应一个UDP包。这个也是伴随TCP窗口管理、拥塞控制等。



### UDP怎么实现可靠性传输
**从应用层角度考虑：**
1. 提供超时重传，能避免数据报丢失。
2. 提供确认序列号，可以对数据报进行确认和排序。

本端：首先在UDP数据报定义一个首部，首部包含**确认序列号和时间戳**，时间戳是用来计算RTT(数据报传输的往返时间)，从何计算出合适的RTO(重传的超时时间)。然后以等-停的方式发送数据报，即收到对端的确认之后才发送下一个的数据报。当时间超时，本端重传数据报，同时RTO扩大为原来的两倍，重新开始计时。
对端：接受到一个数据报之后取下该数据报首部的时间戳和确认序列号，并添加本端的确认数据报首部之后发送给对端。根据此序列号对已收到的数据报进行排序并丢弃重复的数据报。
发送方的处理：
1） 包发送确认后，由于还没有收到确认，先缓存
2） 收到确认包后，从缓存中删除发送的包
3） 接收方将丢失的包通知过来，或者超过一定的时候，若还没有收到确认的包，进行重传（注意，这个由接收线程触发）

接收方的处理：
1） 接收到包的数据，先将数据放到缓存中，a. 若有丢包现象，通知发送方，同时记录丢失的包 b.若是重传的包，从丢失的列表中删除
2） 发送确认包
3） 丢失的包，超时会让发送方再次发送

一些情况分析：
情况1：发送包a，接收方确认a，发送方收到确认：正常
情况2：发送包a，接收方确认a，发送方没有收到确认：发送方会重发此包，接收方收到此包忽略
情况3：发送包a，接收方没有收到a：发送方重发此包
情况4：发送包a，一直收不到确认，超过一定次数或时间后，结束
情况4：发送包a失败，结束


### UDP为什么会乱序
tcp 协议头有 seq 和 ack_seq 用来保证 tcp包的时序, 如果出现缺少其中一块, 会进行重传, 而 udp没有seq 和 ack_seq 来保证, 所以没有


### UDP为什么比TCP快
TCP有拥塞控制、滑动窗口等一系列的算法来保证数据的正确和有序，而UDP就没有这么多工作。


### close_wait作用，如果close_wait不关闭有什么问题？   
在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。通常来讲，CLOSE_WAIT状态的持续时间应该很短，正如SYN_RCVD状态。

**出现大量close_wait的现象**，主要原因是某种情况下对方关闭了socket链接，但是我方忙与读或者写，没有关闭连接。代码需要判断socket，一旦读到0，断开连接，read返回负，检查一下errno，如果不是AGAIN，就断开连接。

一直存在导致端口被占用



## 表示层

## 会话层

## 应用层

### HTTP基于什么  底层使用的什么协议 长连接还是短链接
在**HTTP/1.0**版本中，默认使用的是短连接，也就是说浏览器和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。如果客户端浏览器访问某个HTML或其他类型的Web页中包含其他的web资源，则浏览器每遇到这样一个web资源，就会建立一个HTTP会话

从**HTTP/1.1**版本起，默认使用长连接用以保持连接特性。使用长连接的HTTP协议，会在响应消息报文段加入: Connection: keep-alive。注意：TCP中也有keep alive，但是TCP中的keep alive只是探测TCP连接是否活着，而HTTP中的keep-alive是让一个TCP连接获得更久一点。 
在使用长连接的情况下，当一个网页打开之后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问呢这个服务器上的网页的时候，会继续使用这一条已经建立的连接。当然这个连接不会永久的保持下去，他有一个keep-alive(保活时间)。实现长连接要求客户端和服务器都要支持长连接。

HTTP协议的底层使用**TCP协议**，所以HTTP协议的长连接和短连接在本质上是TCP层的长连接和短连接。由于TCP建立连接、维护连接、释放连接都是要消耗一定的资源，浪费一定的时间。所对于服务器来说，频繁的请求释放连接会浪费大量的时间，长时间维护太多的连接的话又需要消耗资源。所以长连接和短连接并不存在优劣之分，只是适用的场合不同而已。

长连接和短连接的优点和缺点。 
（1）长连接可以节省较多的TCP连接和释放的操作，节约时间，对于频繁请求资源的用户来说，适合长连接。由于有保活功能，当遇到大量的恶意连接时，服务器的压力会越来越大。这时服务器需要采取一些策略，关闭一些长时间没有进行读写事件的的连接。 
（2）短连接对服务器来说管理比较简单，只要存在的连接都是有效连接，不需要额外的控制手段，而且不会长时间的占用资源 。但如果客户端请求频繁的话，会在TCP的建立和释放上浪费大量的时间。

### 输入www.baidu.com发生了什么
第一步 浏览器查找该域名的 IP 地址

第二步 浏览器根据解析得到的IP地址向 web 服务器发送一个 HTTP 请求

第三步 服务器收到请求并进行处理

第四步 服务器返回一个响应

第五步 浏览器对该响应进行解码，渲染显示。

第六步 页面显示完成后，浏览器发送异步请求。

1. 查询IP
浏览器把域名发送给系统默认DNS服务器。如果该服务器本地有缓存，且缓存未过期，则直接返回结果
否则向上一级DNS服务器查询，直到DNS根服务器。DNS协议最终会返回A记录(IPv4)或者AAAA记录(IPv6)或者Alias(别名)等。如果DNS失败，浏览器会提示域名找不到或者DNS错误。

2. 发送HTTP请求
浏览器知道了网址的对应服务器IP地址和端口，然后就通过TCP协议发起网络请求。
通过DNS获取到IP后，目标IP和本机IP分别与子网掩码相与的结果相同，那么它们在一个子网，那么通过ARP协议可以查到目标主机的MAC地址，否则的话，需要通过网关转发，也就是目标MAC是网关的MAC。
请求需要进行编码，生成一个HTTP数据包，依次打上TCP、IP、以太网协议的头部。其中TCP头部主要信息是本机端口和目标端口号等信息，用于标识同一个主机的不同进程，对于HTTP协议，服务器端的默认端口号是80，本机浏览器的话生成一个1024到65535之间的端口号。IP头部主要包含本地IP和目标IP等信息。以太网协议头部主要是双方的MAC地址，目标MAC可以由第一条所诉方法得到。以太网数据包的数据部分，最大长度为1500字节，所以如果IP包太大的话还要拆包，比如IP包5000字节，要分为4包，每一包都包含一个IP头部。












