[TOC]

## 物理层

## 数据链路层

## 网络层

## 传输层
### TCP的流量控制：滑动窗口的原理
滑动窗口协议**允许发送方在停止并等待确认前发送多个数据分组**。由于发送方不必每发一个分组（IP数据包或TCP报文段）就停下来等待确认，因此该协议可以加速数据的传输，增大了吞吐量。

停止等待协议是最简单但也是最基础的数据链路层协议。与滑动窗口协议不同的是停止等待协议就是每发送完一个分组就停止发送，等待对方的确认，在收到确认后再发送下一个分组。当发送窗口和接收窗口的大小都等于**1**时，就是停止等待协议。

TCP的可靠数据传输服务确保进程从接收缓冲区中读出的数据流是正确地，有序的，不重复的，即读出的字节流与连接的另一方系统发送的字节流是完全一样的，但是实际上接收方应用进程不一定时刻都在读数据，那么如果应用进程读取数据相当慢，而发送方发送的数据太多、太快，就很容易使接收方的接收缓冲区溢出。所以**TCP采用大小可变的滑动窗口给应用程序提供流量控制服务**，用以消除接收缓冲区溢出的可能。实际上TCP报文段头部的16位窗口字段写入的数值就是接收方当前给对方设置的发送窗口的上限，发送窗口在连接建立时由双方商定，但是在通信过程中，接收方根据自己的接收缓冲区资源大小随时动态的调整对方发送窗口的上限（滑动窗口即可以滑动滴）。

流量控制（用滑动窗口实现）就是让发送方的发送速率不要太快，要让接收方来得及接收。

TCP连接发送方发送一个数据报，对端会进行确认在发送下一个数据包。

举个例子：TCP通信是全双工的，这里为了方便理解，就以一个方向为例，假设A为发送方，B为接收方。A会有一个发送窗口，B有一个接收窗口。在连接建立的时候B告诉A其接收窗口是400字节，因此发送方的发送窗口不能超过接收方给的接收窗口大小。（假设一个报文段100字节，报文段序号初始值为1.图中大写ACK表示头部中的确认位ACK，小写ack表示确认字段的值）
![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B601.png)

为了便于大家看，我们采用另一种方式描述发送窗口，假设A现在收到B的确认报文段，窗口是20字节，确认号是31（表示B期望收到的下一个序号是31，而序号30为止的数据已经收到了），根据此条件，A构造出自己的发送窗口，如下图：
![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B602.png)

**发送窗口表示在没有收到B确认的情况下，A也可以连续把发送窗口的数据发送出去**。但是已经发送过的数据在未收到确认之前，它还需要暂时保留，以便于超时重传时使用。发送窗口越大，它就可以在收到对方确认之前发送更多的数据，因而获得更高的传输效率。（但是接收方要来得及处理之前的数据）

发送窗口的位置由窗口前沿和后沿的位置共同确定。
它后沿变化有两种，（1）不动（没有收到新的确定）（2）前移（收到新的确认）；

前沿是不断向前移动的，但也可能不动
（1）不动（没有收到新确认，对方窗口也不变）
（2）不动（收到新的确认，对方的应用层没有读取数据，接收窗口缩小了，使前沿正好不变，后沿前移窗口就变小了）

假定A发送了序号为31～41的数据。这时，发送窗口的位置并未改变，发送窗口内靠后的11个字节（黑色部分）表示 已发送但未收到确认。
![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B603.png)

即小于P1的是已发送并收到确认的序号，而大于P3的是不允许发送的部分。
P3-P1=A的发送窗口
P2-P1=已发送但是未接收到确认的字节数
P3-P2=允许发送但是未发送的字节数（可用窗口或有效窗口）

再看B的接收窗口大小是20，在接收窗口外面到30号位置的数据是接收并确认的，因此可以丢弃。在接收窗口中，B收到了32和33的数据（白色的是没有接收到的），但它们不是按序到达的，因为并没有收到31号数据。B只能对按序达收到的数据中的最高序号给出确认，因此B发送的确认报文字段的确认号依然是31号（确认号就是告诉发送方期望下一次收到数据包的序号）。

现在假定B收到了序号为31的数据，并把31～33的数据交付主机，然后B删除这些数据。接着把窗口向前移动3个序号，如下图，同时给a发送确认，其中的窗口值仍为20，但确认号变为34。表明B已经收到序号33为止的数据。

![](https://raw.githubusercontent.com/Hewie8023/zhengli/master/image/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B604.png)

当A发送完窗口内的所有数据后，未收到任何确认时，窗口内就没有可发送的数据。经过一段时间后（超时计时器），若仍未收到确认，A将会重新发送。

此外发送方和接收方都有自己的缓冲区
**发送缓冲区存放**：
1、发送发TCP准备发送的数据
2、TCP已发送但尚未收到确认的数据（为超时重传准备）

**接收缓冲区存放**：
1、按序到达但未被应用程序读取的数据
2、未按序到达的数据

实际上发送窗口大小不仅仅是由接收端决定的，其还受网络的拥塞程度决定。发送窗口=MIN{接收窗口，拥塞窗口}


### 既然有了拥塞控制,为什么还会有拥塞比如游戏卡顿
https://zhuanlan.zhihu.com/p/59778587
路由器只是把溢出的流量丢弃处理，其他的什么都不做。
源主机发现丢包了，就会将流量降速差不多一半，这就是流量拥塞控制。
但是，是先发生“路由器流量溢出（丢包）”，然后才触发了“源主机的流量拥塞控制”。
源主机的流量拥塞控制（Congestion Control）机制，永远都无法避免路由节点的网络拥塞，从而造成的流量溢出（丢包）！

### TCP粘包、拆包
粘包问题主要还是因为接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。

发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一个TCP段。若连续几次需要send的数据都很少，通常TCP会根据negal优化算法把这些数据合成一个TCP段后一次发送出去，这样接收方就收到了粘包数据。

两种粘包情况：
1. 发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据了很小，会合到一起，产生粘包）
2. 接收方不及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包） 

两种拆包情况：
1. 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
2. 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。

**粘包、拆包解决办法**
通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：
1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。


#### UDP会不会粘包
TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。

### TCP怎么实现的


### TCP三次握手、四次挥手


### TCP和UDP各自的特点

### UDP怎么实现可靠性传输

### UDP为什么会乱序

### UDP为什么比TCP快

### close_wait作用，如果close_wait不关闭有什么问题？   



## 表示层

## 会话层

## 应用层

### HTTP基于什么  底层使用的什么协议 长连接还是短链接
在**HTTP/1.0**版本中，默认使用的是短连接，也就是说浏览器和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。如果客户端浏览器访问某个HTML或其他类型的Web页中包含其他的web资源，则浏览器每遇到这样一个web资源，就会建立一个HTTP会话

从**HTTP/1.1**版本起，默认使用长连接用以保持连接特性。使用长连接的HTTP协议，会在响应消息报文段加入: Connection: keep-alive。注意：TCP中也有keep alive，但是TCP中的keep alive只是探测TCP连接是否活着，而HTTP中的keep-alive是让一个TCP连接获得更久一点。 
在使用长连接的情况下，当一个网页打开之后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问呢这个服务器上的网页的时候，会继续使用这一条已经建立的连接。当然这个连接不会永久的保持下去，他有一个keep-alive(保活时间)。实现长连接要求客户端和服务器都要支持长连接。

HTTP协议的底层使用**TCP协议**，所以HTTP协议的长连接和短连接在本质上是TCP层的长连接和短连接。由于TCP建立连接、维护连接、释放连接都是要消耗一定的资源，浪费一定的时间。所对于服务器来说，频繁的请求释放连接会浪费大量的时间，长时间维护太多的连接的话又需要消耗资源。所以长连接和短连接并不存在优劣之分，只是适用的场合不同而已。

长连接和短连接的优点和缺点。 
（1）长连接可以节省较多的TCP连接和释放的操作，节约时间，对于频繁请求资源的用户来说，适合长连接。由于有保活功能，当遇到大量的恶意连接时，服务器的压力会越来越大。这时服务器需要采取一些策略，关闭一些长时间没有进行读写事件的的连接。 
（2）短连接对服务器来说管理比较简单，只要存在的连接都是有效连接，不需要额外的控制手段，而且不会长时间的占用资源 。但如果客户端请求频繁的话，会在TCP的建立和释放上浪费大量的时间。

### 输入www.baidu.com发生了什么






